import glob
import re
import pandas as pd
from src.utils.util import clean_groups
from collections import defaultdict
import os
import subprocess

class MatlabProgramRunner:
    def __init__(self, conversion_years):
        self.conversion_years = conversion_years

    def write_matlab_params(self):
        # Get the list of files from the correct directory
        matrices_dir = "/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/matrices"
        files = glob.glob(os.path.join(matrices_dir, "*.csv"))

        # Extract the max groups
        result = self.extract_max_groups(files)

        # Prepare the output strings
        start_years = []
        end_years = []
        max_groups = []

        for (start, end), max_group in sorted(result.items()):
            start_years.append(str(start))
            end_years.append(str(end))
            max_groups.append(str(max_group))  # We'll convert these back to integers in the output

        # Create the output directory if it doesn't exist
        output_dir = "/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/temp"
        os.makedirs(output_dir, exist_ok=True)

        # Write to the file
        output_file = os.path.join(output_dir, "matlab_script_params.txt")
        with open(output_file, 'w') as f:
            f.write("# Generated by generator_params.py\n\n")
            # Write each parameter on a new line
            f.write("START_YEARS=\"" + " ".join(start_years) + "\"\n")
            f.write("END_YEARS=\"" + " ".join(end_years) + "\"\n")
            f.write("MAX_GROUPS=\"" + " ".join(max_groups) + "\"\n")

        print(f"Parameters written to {output_file}")


    def extract_max_groups(self, filenames):
        # Dictionary to store max group number for each year pair
        max_groups = defaultdict(int)
        
        # Regex pattern to extract years and group numbers
        pattern = r'start\.(\d+)\.end\.(\d+)\.group\.(\d+)\.csv'
        
        for filename in filenames:
            match = re.search(pattern, filename)
            if match:
                start_year = int(match.group(1))
                end_year = int(match.group(2))
                group_num = int(match.group(3))
                
                # Update max group if larger
                year_pair = (start_year, end_year)
                max_groups[year_pair] = max(max_groups[year_pair], group_num)
        
        return max_groups
    

    def run_matlab_optimization(self):
        script_dir = "/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/src/scripts/"
        bash_script = os.path.join(script_dir, "run_matlab_optimization.sh")
        
        # Make sure the script is executable
        os.chmod(bash_script, 0o755)
        
        # Run the bash script using subprocess
        try:
            result = subprocess.run(['bash', bash_script], 
                                check=True,
                                capture_output=True,
                                text=True)
            
            print("MATLAB optimization completed successfully")
            print("Output:", result.stdout)
            if result.stderr:
                print("Errors:", result.stderr)
                
        except subprocess.CalledProcessError as e:
            print(f"Error running MATLAB optimization: {e}")
            print("Error output:", e.stderr)
        except Exception as e:
            print(f"Unexpected error: {e}")


class GroupWeights():
    def __init__(self, conversion_years):
        self.conversion_years = conversion_years

    def run(self):
        for source_class, start_year, target_class, end_year in self.conversion_years:
            print(f"source class {source_class} and target class {target_class}")
            combined_result = pd.DataFrame()
            results = glob.glob(f"/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/conversion_weights/conversion.weights.start.{start_year}.end.{end_year}.group.*.csv")
            if not results:
                raise ValueError("Missing conversion weights data, need to run step 4")
            for file in results:
                match = re.search(r'group\.(\d+)\.csv$', str(file))
                if not match:
                    continue

                gid = match.group(1)

                # try:
                conversion_group = pd.read_csv(f"/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/matrices/conversion.matrix.start.{start_year}.end.{end_year}.group.{gid}.csv",
                                            dtype={'code.source': str})

                # Load weights and conversion matrix
                weights = pd.read_csv(file, header=None)

                if source_class.startswith("H"):
                    detailed_product_level = 6
                else:
                    detailed_product_level = 4
                # Standardize source product codes
                conversion_group['code.source'] = conversion_group['code.source'].apply(
                    lambda x: x.zfill(detailed_product_level) if len(x) < detailed_product_level and x != "TOTAL" else x
                )

                conversion_group = conversion_group.set_index('code.source')            
                weight_df = pd.DataFrame(weights.values, index=conversion_group.index,columns=conversion_group.columns)

                # Convert to long format
                weight_long = weight_df.reset_index().melt(
                    id_vars='code.source',var_name='code.target',value_name='weight'
                ).astype({'code.source': str, 'code.target':str, 'weight': float})
                

                weight_long['group_id'] = gid
                combined_result = pd.concat([combined_result, weight_long])
                # except:
                #     print("failed")
            groups = pd.read_csv(f"/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/concordance_groups/from_{source_class}_to_{target_class}.csv", 
                                dtype={source_class: str, target_class: str})
            # add back products that did not require optimization and thus never assigned a group id
            non_grouped_products = groups[groups['group.id'].isna()]
            non_grouped_products = clean_groups(non_grouped_products, source_class, target_class)

            non_grouped_products = non_grouped_products[['group.id','code.source','code.target']]
            non_grouped_products['weight'] = 1
            non_grouped_products = non_grouped_products.rename(columns={"group.id":"group_id"})
            combined_result = pd.concat([combined_result, non_grouped_products])
            
            combined_result[['code.target','code.source']] = combined_result[['code.target','code.source']].astype(str)
            combined_result = combined_result.rename(columns={"code.target":target_class,"code.source":source_class})
                    
            print(f"saving {source_class}:{target_class}.csv")
            combined_result = combined_result[combined_result.weight!=0]
            combined_result.to_csv(f"/n/hausmann_lab/lab/atlas/bustos_yildirim/weights_generator/generator/data/output/grouped_weights/grouped_{source_class}:{target_class}.csv", index=False)       
